---
title: "Predicting Genetic Disorders"
author:
  Emma Oo^[University of San Diego, eoo@sandiego.edu], Sindhu Bhattarai^[University of San Diego, sbhattarai@sandiego.edu], Dave Friesen^[University of San Diego, dfriesen@sandiego.edu]
date: "06/27/2022"
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output:
  html_document:
    css: "style.css"
  pdf_document: default
---

<style>
.main-container {
  max-width: 1024px;
}
</style>


### Objective and Hypothesis

##### [. . .]


```{r setup, echo = FALSE, message = FALSE}
# Load R libraries
library(caret)
library(DescTools)
library(e1071)

# Expand output width and minimize exp notation
options(width = 150)
options(scipen = 100)
options(digits = 1)

# Set style defaults
knitr::opts_chunk$set(class.source = "source")
knitr::opts_chunk$set(class.output = "output")
knitr::opts_chunk$set(fig.width = 6.5, fig.height = (6.5 * .7), fig.align = "center")
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NA)
```


### Data Load and Validation

```{r data_load_validation}
# Load dataset(s)
gd_df <- read.csv("../data/train_genetic_disorders.csv", header = TRUE)

# Data validation and understanding, including structure, content, and statistical characteristics covered below
```


###### Data Structure Review

```{r data_structure}
# Summarize base dataset and [optionally] sample rows
str(gd_df)
#head(gd_df, 3)
```


###### Preliminary Feature Reduction (clearly n/a to Objective and Hypothesis)

```{r prelim_feature_reduction}
# Define n/a columns and subset dataframe; Note retaining "some" informational variables like "Institute.Name" for
#   possible descriptive analytic purposes
drop_cols <- c("Patient.Id",
               "Patient.First.Name",
               "Family.Name",
               "Father.s.name",
               "Institute.Name",
               "Location.of.Institute",
               "Status",
               "Test.1",
               "Test.2",
               "Test.3",
               "Test.4",
               "Test.5",
               "Parental.consent",
               "Place.of.birth")
gd_df <- gd_df[ , !(names(gd_df) %in% drop_cols)]
```


###### Class Target and Label Review

```{r class_target_label_review}
# Check for missing labels; set aside where missing
missing_target <- which(is.na(gd_df$Disorder.Subclass) | (gd_df$Disorder.Subclass == ""))
cat("Rows pre-subset for missing labels: ", format(nrow(gd_df), format = "d", big.mark = ","), sep = "")
gd_hold_df <- gd_df[missing_target, ]
gd_df <- gd_df[-missing_target, ]
cat("Held rows with missing labels: ", format(nrow(gd_hold_df), format = "d", big.mark = ","), sep = "")
cat("Net rows (labeled): ", format(nrow(gd_df), format = "d", big.mark = ","), sep = "")

# Show frequency distribution for [prospective] target class(es)
show_frequency <- function(desc, c) {
  t <- as.data.frame(prop.table(table(c)))
  colnames(t) <- c("Class", "Frequency")
  cat(desc, "\n"); print(t[order(-t$Freq, t$Class), 1:2], row.names = FALSE)
}
show_frequency("Pre-Split Frequency Distribution", gd_df$Disorder.Subclass)

# Move the target class to "top" of dataframe so column removals don't impact
gd_df <- gd_df[ , c(ncol(gd_df), 1:(ncol(gd_df) - 1))]
target_col = 1



gd_df$Disorder.Subclass <- gsub("'", "", gd_df$Disorder.Subclass, fixed = TRUE)
gd_df$Disorder.Subclass <- gsub(" ", ".", gd_df$Disorder.Subclass, fixed = TRUE)
gd_df$Disorder.Subclass <- gsub("-", ".", gd_df$Disorder.Subclass, fixed = TRUE)



```


### Data Splitting

```{r data_splitting}
# Split data 80/20 train/test, using caret's inherent stratified split to compensate for class imbalance
set.seed(1)
train_index <- createDataPartition(gd_df$Disorder.Subclass, times = 1, p = 0.80, list = FALSE)
train_df <- gd_df[train_index, ]
test_df <- gd_df[-train_index, ]
show_frequency("Post-Split Frequency Distribution (Train)", train_df$Disorder.Subclass)
```


### Data Cleaning (and reduction)


###### Data (Sample) Characteristic Review for Pre-Processing
(Suppressing custom code for simplicity)

```{r data_univariate, echo = FALSE}
# Note this function is generic and doesn't look for more intelligent "blank" values like "no record",
#   "not available", etc.
is_blank <- function(x) {
  classof_x <- class(x)
  result <-
    !is.na(x) &
    (((classof_x == "character") & (x == "")) |
     ((classof_x %in% c("integer", "numeric")) & (x == 0)))
  return(result)
}

# Function to format percentages (only when value exists)
format_percent <- function(x) {
  result <- formatC(x * 100, digits = 0, width = 5, format = "d", zero.print = FALSE)
  if (x != 0) result <- paste(result, "%", sep = "")
  return(result)  
}

# Function to not output NaNs from third-party functions in lapply() below
nan_replace_0 <- function(x) {
  if (is.nan(x)) result <- 0 else result = x
  return(result)
}

# Function to Generate a summary of base dataset
univariate <- function(df) {
  rowcount <- nrow(df)
  ua <- do.call(rbind, lapply(df, function(x) c(
    colnames(x),
    class(x),
    format_percent(sum(is.na(x)) / rowcount),
    format_percent(sum(is_blank(x)) / rowcount),
    formatC(length(unique(na.omit(x))),
            digits = 0, width = 7, format = "d", big.mark = ",", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), min(na.omit(x)), 0),
            digits = ifelse(is.double(x), 3, 0), width = 7, format = "f", big.mark = ",", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), max(na.omit(x)), 0),
            digits = ifelse(is.double(x), 3, 0), width = 7, format = "f", big.mark = ",", zero.print = FALSE),
    formatC(ifelse(is.double(x), mean(na.omit(x)), 0),
            digits = 3, width = 7, format = "f", big.mark = ",", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), median(na.omit(x)), 0),
            digits = ifelse(is.double(x), 3, 0), width = 7, format = "f", big.mark = ",", zero.print = FALSE),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) < (quantile(na.omit(x), 0.25) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) > (quantile(na.omit(x), 0.75) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    formatC(ifelse(is.numeric(x), nan_replace_0(skewness(na.omit(x))), 0),
            digits = 3, width = 8, format = "f", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), nan_replace_0(kurtosis(na.omit(x))), 0),
            digits = 3, width = 8, format = "f", zero.print = FALSE))))
  colnames(ua) <- c(
    "Type",
    format("NA", justify = "right", width = 6),
    format("BlankZ", justify = "right", width = 6),
    format("Unique", justify = "right", width = 7),
    format("Min", justify = "right", width = 7),
    format("Max", justify = "right", width = 7),
    format("Mean", justify = "right", width = 7),
    format("Median", justify = "right", width = 7),
    format("Outlier<", justify = "centre", width = 8),
    format(">Outlier", justify = "centre", width = 8),
    format("Kurtosis", justify = "right", width = 8),
    format("Skewness", justify = "right", width = 8))
  row.names(ua) <- lapply(row.names(ua),
                          function(x) if (nchar(x) > 20) return(paste(substr(x, 1, 17), "...", sep = ""))
                          else return(x))
  { cat(
    "Summary Univariate Analysis (",
    formatC(rowcount, big.mark = ","), " observations)\n",
    sep = "")
    print(noquote(ua))
  }
}
```


```{r data_characteristics}
# Generate a summary (cursory) view of base dataset for initial understanding and pre-processing direction
univariate(train_df)
```


###### Missing Values

```{r missing_values}
# Genes.in.mother.s.side, Paternal.gene, Blood.cell.count..mcL., Status - n/a

# Impute basic integer values with medians
medianf <- function(x) {
 result <- median(x, na.rm = TRUE)
 if (is.integer(x))
   result <- as.integer(result)
 return(result)
}
median_cols = c("Patient.Age", "Mother.s.age", "Father.s.age", "No..of.previous.abortion")
for (n in median_cols) {
  train_df[n][is.na(train_df[n])] <- apply(train_df[n], 2, medianf)
  test_df[n][is.na(test_df[n])] <- apply(test_df[n], 2, medianf)
}
                                           
# Impute categorical blanks with common "notprovided"; note we could also impute these with categorical mode,
#   or most frequent categorical value of each column using the cmode() function below
cols_tofill <- c("Inherited.from.father",
                 "Maternal.gene",
                 "Respiratory.Rate..breaths.min.",
                 "Heart.Rate..rates.min",
                 "Follow.up",
                 "Gender",
                 "Birth.asphyxia",
                 "Autopsy.shows.birth.defect..if.applicable.",
                 "Folic.acid.details..peri.conceptional.",
                 "H.O.serious.maternal.illness",
                 "H.O.radiation.exposure..x.ray.",
                 "H.O.substance.abuse",
                 "Assisted.conception.IVF.ART",
                 "History.of.anomalies.in.previous.pregnancies",
                 "Birth.defects",
                 "Blood.test.result")
train_df[cols_tofill][train_df[cols_tofill] == ""] <- "notprovided"
test_df[cols_tofill][test_df[cols_tofill] == ""] <- "notprovided"

cmode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

# Impute what appear to be masked "flag" columns iwth placeholder -1 values. . .
flag_cols <- c("Symptom.1", "Symptom.2", "Symptom.3", "Symptom.4", "Symptom.5")
train_df[flag_cols][is.na(train_df[flag_cols])] <- as.integer(-1)
test_df[flag_cols][is.na(test_df[flag_cols])] <- as.integer(-1)

# Impute mean for one numeric column
train_df$White.Blood.cell.count..thousand.per.microliter.[is.na(train_df$White.Blood.cell.count..thousand.per.microliter.)] <-
  mean(train_df$White.Blood.cell.count..thousand.per.microliter., na.rm = TRUE)
test_df$White.Blood.cell.count..thousand.per.microliter.[is.na(test_df$White.Blood.cell.count..thousand.per.microliter.)] <-
  mean(test_df$White.Blood.cell.count..thousand.per.microliter., na.rm = TRUE)

# Note not using knnImpute for the limited number of numerical [prospective] features given that it
#   centers/scales, which is illogical for the values in this dataset
#pp <- preProcess(train_df[ , -target_col, drop = FALSE], method = "knnImpute", k = 10)
#train_df[ , -target_col] <- predict(pp, train_df[ , -target_col, drop = FALSE])
#test_df[ , -target_col] <- predict(pp, test_df[ , -target_col, drop = FALSE])

# Last on the list: Genetic.Disorder - we're not classifying to this but it is relevant/informational as a
#   superclass to the target Disorder.Subclass and shuold ultimately be imputed using similar Disorder.Subclass
#   observations which do have valid Genetic.Disorder values
```


###### Feature Updates (including variable types/formats, names)

```{r feature_updates}
# Re-type variables
factor_cols <- c("Genes.in.mother.s.side",
                 "Inherited.from.father",
                 "Maternal.gene",
                 "Paternal.gene",
                 "Respiratory.Rate..breaths.min.",
                 "Heart.Rate..rates.min",
                 "Follow.up",
                 "Gender",
                 "Birth.asphyxia",
                 "Autopsy.shows.birth.defect..if.applicable.",
                 "Folic.acid.details..peri.conceptional.",
                 "H.O.serious.maternal.illness",
                 "H.O.radiation.exposure..x.ray.",
                 "H.O.substance.abuse",
                 "Assisted.conception.IVF.ART",
                 "History.of.anomalies.in.previous.pregnancies",
                 "Birth.defects",
                 "Blood.test.result",
                 "Disorder.Subclass")
train_df[factor_cols] <- lapply(train_df[factor_cols], factor)
test_df[factor_cols] <- lapply(test_df[factor_cols], factor)
# Note dummy variables may be introduced below for e.g., logistic regression

# Simplify variable naming
# [TBD]

# Generate updated summary of base dataset
univariate(train_df)
```


###### Zero/Near-Zero Variances

```{r near_zero_z_variances}
# n/a for this dataset
```


###### Duplicate Values

```{r duplicate_values}
# n/a for this dataset
```


###### "Noisy" Data

```{r noisy_data}
# n/a for this dataset
```


### Data Transformation


###### Centering/Scaling (standardizing/normalizing)

```{r centering_scaling}
# n/a for this dataset?
```


###### Statistical Characteristics (including distribution, skewness, outliers)

```{r statistical_characteristics}
#summary(train_df)
```


###### Other Feature Engineering (transformation, aggregation, enrichment)

```{r other_feature_engineering}
# n/a for this dataset?
```


### Multivariate Analysis (and reduction)


###### Collinearity and Dependencies

```{r collinearity_and_dependencies}
# Calculate Cramer's V "measure of association" between nominal factor variables (uses Chi-square statistic)
cscorr <- PairApply(train_df[ , sapply(train_df, is.factor)], CramerV, symmetric = TRUE)

# Shorten variable names for ease of reviewing output matrix
rn <- rownames(cscorr)
for (n in 1:length(rownames(cscorr))) {
  rn[n] <- paste(rownames(cscorr)[n], " (", AscToChar(64 + n), ")", sep = "")
  rownames(cscorr)[n] <- paste(AscToChar(64 + n))
}
for (n in 1:length(colnames(cscorr)))
  colnames(cscorr)[n] <- paste(AscToChar(64 + n))

# Show master list of variable names along with output ("correlation") matrix
cat(rn, sep = "\n")
cscorr
```


###### Predictor Transformations (e.g., PCA)

```{r predictor_transformations}
```


### Modeling


###### Feature Selection

```{r feature_selection}
```


###### Training, Testing (validating), and Evaluation (iteration n)

```{r training_testing_evaluation}
# Create common control for models
set.seed(1)
fit_control <- trainControl(method = "cv",
                            number = 10,
                            savePredictions = "all",
                            classProbs = TRUE,
                            summaryFunction = multiClassSummary)

# Select predictors (features) for lr model
predictor_cols <- c("Genes.in.mother.s.side",
                    "Inherited.from.father",
                    "Maternal.gene",
                    "Paternal.gene",
                    "Mother.s.age",
                    "Father.s.age",
                    "History.of.anomalies.in.previous.pregnancies")
#*Genes.in.mother.s.side
#*Inherited.from.father
#*Maternal.gene
#*Paternal.gene
#Blood.cell.count..mcL.
#*Mother.s.age
#*Father.s.age
#Respiratory.Rate..breaths.min.
#Heart.Rate..rates.min
#Follow.up
#Gender
#Birth.asphyxia
#Autopsy.shows.birth.defect..if.applicable.
#Folic.acid.details..peri.conceptional.
#H.O.serious.maternal.illness
#H.O.radiation.exposure..x.ray.
#H.O.substance.abuse
#Assisted.conception.IVF.ART
#*History.of.anomalies.in.previous.pregnancies
#No..of.previous.abortion
#Birth.defects
#White.Blood.cell.count..thousand.per.microliter.
#Blood.test.result
#Symptom.1
#Symptom.2
#Symptom.3
#Symptom.4
#Symptom.5
  
# Train logistic regression model
invisible(capture.output(
  lr_fit <- train(x = train_df[ , predictor_cols, drop = FALSE],
                  y = train_df$Disorder.Subclass,
                  method = "multinom",
                  metric = "ROC",
                  trControl = fit_control)
))
#lr_fit
#lr_fit$finalModel

# Generate confusion matrix
lr_cm <- confusionMatrix(lr_fit, norm = "none")

# Simplify class names for more coherent confusion matrix, and output
for (n in 1:length(rownames(lr_cm$tab)))
  rownames(lr_cm$table)[n] <- paste(rownames(lr_cm$table)[n], " (", AscToChar(64 + n), ")", sep = "")
for (n in 1:length(colnames(lr_cm$tab)))
  colnames(lr_cm$table)[n] <- paste("Class", AscToChar(64 + n))
lr_cm

# Plot ROC curve
#lr_roc <- roc(response = lr_fit$pred$obs,
#              predictor = lr_fit$pred$Yes,
#              levels = rev(levels(lr_fit$pred$obs)))
#if (show_output) { plot(lr_roc, legacy.axes = TRUE, main = "LR ROC Curve",
#                        xlab = "Fall Positive Rate (Specificity)",
#                        ylab = "True Positive Rate (Sensitivity)") }
#if (show_output) { lr_roc$auc }

# Check for most important predictors
plot(varImp(lr_fit, scale = FALSE), top = 10, main = "LR Important Predictors")
varImp(lr_fit)

# Establish test_results dataframe
test_results <- data.frame(obs = test_df$Disorder.Subclass,
                           model_2_tbd = 0.0,
                           model_3_tbd = 0.0,
                           model_4_tbd = 0.0,
                           model_5_tbd = 0.0)

# Validate model vs. test data
test_results$lr <- predict(lr_fit, test_df[ , predictor_cols, drop = FALSE])
```


###### Optimization, Tuning, Selection

```{r optimization_tuning_selection}
```
